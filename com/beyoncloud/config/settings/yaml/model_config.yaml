model_config:
  environments:
    dev:
      llm_model:
        selected_model:
          default_model: llama-3.2-3B-instruct
        models:
          - model_alias: llama-3.2-3B-instruct
            model_id: meta-llama/Llama-3.2-3B-Instruct
            model_type: llm
            family: llama
            task: text-generation
            max_new_tokens: 256
            temperature: 0.8
            do_sample: False
            top_p: 0.9
            repetition_penalty: 1.1
            return_full_text: False
          - model_alias: mistral-7B-v0.3
            model_id: mistralai/Mistral-7B-v0.3
            model_type: llm
            family: mistralai
            max_new_tokens: 256
            temperature: 0.8
            do_sample: False
            top_p: 0.9
            repetition_penalty: 1.1
            return_full_text: False


chunk_size: 500
chunk_overlap: 20
max_chunk_tokens: 100
query_retrieval_top_k: 10
retrieval_top_k: 6
score_threshold: 0.5

# LLM Model
local_llama_model: E:\\Models\\meta-llama_Llama-3.2-3B-Instruct
#local_llama_model: D:\\model\\meta-llama_Llama-3.2-3B-Instruct
