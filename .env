APP_ENV=stage

# Config
BC_ROOT_PATH=E:/beyoncloud/common
CONFIG_FILE_PATH="/config"
MT_ID_DFN_CONFIG_TEMPLATE=mt_id_dfn_template
MT_ORG_PROMPT_CONFIG_TEMPLATE=mt_org_prompt_template

PRELOAD_TEMPLATES=MT_ID_DFN_CONFIG_TEMPLATE, MT_ORG_PROMPT_CONFIG_TEMPLATE

#Load all templates Y/N
LOAD_ALL_TEMPLATES=N

# Schema prompt generation filepath
SCHEMA_PROMPT_DIR_PATH="data/prompt/schema"

# Inference response file generation path
CLARIDATA_DIR_PATH="data/claridata"


#########################################
#  Service Discovery Config           
#########################################
MODEL_INFERENCE_SERVICE="modelinference-service"

################################
# Consul Service Discovery
################################
CONSUL_SERVICE_WATCHER_TIMEOUT=600
CONSUL_SERVICE_WATCHER_INTERVAL=2
CONSUL_SERVICE_GRPC_PREFER="grpc_port"

# Model Configuration
MODEL_MAX_NEW_TOKENS=2304
MODEL_TEMPERATURE=0.2
MODEL_TOP_P=0.9
REPETITION_PENALTY=1.05